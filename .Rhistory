geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
library(dplyr)
library(magrittr)
library(qrcode)
library(ggplot2)
library(lattice)
data <- read.csv("fisheries.csv")
# Use basic R to create a histogram on capture
hist(data$capture)
# Use ggplot to create a histogram on capture
ggplot(data, aes(x=capture)) +
geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
# Use lattice to create a histogram on capture
histogram(data, main="Lattice Histogram", xlab="capture", ylab="Frequency", type="count)
# Use basic R to create a histogram on capture
hist(data$capture)
# Use ggplot to create a histogram on capture
ggplot(data, aes(x=capture)) +
geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
# Use lattice to create a histogram on capture
histogram(~data, main="Lattice Histogram", xlab="vapture", ylab="Frequency", type="count
# Use basic R to create a histogram on capture
hist(data$capture)
# Use ggplot to create a histogram on capture
ggplot(data, aes(x=capture)) +
geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
# Use lattice to create a histogram on capture
histogram(~data, main="Lattice Histogram", xlab="capture", ylab="Frequency", type="count)
# Use lattice to create a histogram on capture
barchart(~table(cont),data=data)
# Use lattice to create a histogram on capture
barchart(~table(capture),data=data)
# Use basic R to create a histogram on capture
hist(data$capture)
# Use ggplot to create a histogram on capture
ggplot(data, aes(x=capture)) +
geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
# Use lattice to create a histogram on capture
barchart(~table(capture),data=data)
# Use lattice to create a histogram on capture
barchart(~table(country),data=data)
# Use lattice to create a histogram on capture
barchart(~table(country[1:20]),data=data)
# Use lattice to create a histogram on capture
barchart(~table(capture[1:20]),data=data)
# Use basic R to create a histogram on capture
hist(data$capture)
# Use ggplot to create a histogram on capture
ggplot(data, aes(x=capture)) +
geom_histogram(fill="lightblue", color="black", bins=30) +
ggtitle("ggplot2 Histogram") +
xlab("Values") +
ylab("Frequency")
# Use lattice to create a histogram on capture
barchart(~table(capture[1:20]),data=data)
data2 <- data %>% pivot_longer(c("capture", "aquaculture"), names_to = "year", values_to = "cases")
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(qrcode)
library(lattice)
library(wordcloud2)
install.packages("wordcloud2")
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(qrcode)
library(lattice)
library(wordcloud2)
data <- read.csv("fisheries.csv")
data2 <- data %>% pivot_longer(c("capture", "aquaculture"), names_to = "year", values_to = "cases")
View(data2)
data2 <- data %>% pivot_longer(c("capture", "aquaculture"), names_to = "type", values_to = "number")
ggplot(data, aes(x=capture, y=aquaculture)) +
geom_point()
View(data)
# Create a word cloud on capture and aquaculture
word_cloud_data <- data %$% data.frame(country)
wordcloud2(data = country, size = 4)
# Create a word cloud on capture and aquaculture
word_cloud_data <- data %$% data.frame(country)
wordcloud2(data = word_cloud_data, size = 4)
# Create a word cloud on capture and aquaculture
word_cloud_data <- data %$% data.frame(country)
wordcloud2(data = word_cloud_data[1], size = 4)
# Create a word cloud on capture and aquaculture
word_cloud_data <- data %$% data.frame(country)
wordcloud2(data = word_cloud_data[, 1], size = 4)
# Create a word cloud on capture and aquaculture
word_cloud_data <- data %$% data.frame(country)
wordcloud2(data = word_cloud_data[1, 1], size = 4)
View(word_cloud_data)
?r
??r
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert the text to a corpus
docs <- Corpus(VectorSource(text))
install.packages(c("wordcloud", "tm", "slam"))
library(wordcloud)
library(tm)
library(tm)
install.packages("tm")
library(tm)
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert the text to a corpus
docs <- Corpus(VectorSource(text))
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Transform the corpus
docs <- tm_map(docs, content_transformer(tolower))
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Create a term-document matrix
dtm <- TermDocumentMatrix(text)
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Remove stop words
stop_words <- stopwords("en")
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
word_table <- as.data.frame(word_freqs)
wordcloud(words=word_table$word, freq=word_table$freq, min.freq=1, max.words=100,
colors=brewer.pal(8, "Dark2"), random.order=FALSE)
wordcloud(words=word_table$word, freq=word_table$freq, min.freq=1,
colors=brewer.pal(8, "Dark2"), random.order=FALSE)
?wordcloud
wordcloud(words=word_table$word, freq=word_table$freq, max.words = 20,
colors=brewer.pal(8, "Dark2"), random.order=FALSE)
library(RColorBrewer)
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Remove English stop words
stop_words <- stopwords("en")
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
wordcloud(words=word_table$word, freq=word_table$freq, max.words = 20,
colors=brewer.pal(8, "Dark2"), random.order=FALSE)
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
word_table <- as.data.frame(word_freqs)
wordcloud(words=word_table$word, freq=word_table$freq, max.words = 20,
colors=brewer.pal(8, "Dark2"), random.order=FALSE)
library(RColorBrewer)
library(wordcloud2)
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(qrcode)
library(lattice)
data <- read.csv("fisheries.csv")
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
word_table <- as.data.frame(word_freqs)
wordcloud2(words=word_table$word, freq=word_table$freq)
wordcloud2(data = word_table, words=word_table$word, freq=word_table$freq)
wordcloud2(data = word_table, size = 10)
View(word_table)
wordcloud2(data = word_table, size = 2)
# Generate the QR code for my github page
github_url <- "https://github.com/TML17"
plot(github_url)
# Generate the QR code for my github page
github_url <- "https://github.com/TML17"
plot(github_url)
# Generate the QR code for my github page
github_url <- "https://github.com/TML17"
plot(qr_code(github_url))
# Generate the QR code for my linkedin page
linkedin_url <- "https://www.linkedin.com/in/chenxing-liu-916730204/"
plot(qr_code(linkedin_url))
install_tinytex()
install.packages('tinytex')
shiny::runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Lab4')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Lab4')
data <- read.csv("fisheries.csv")
data <- read.csv("fisheries.csv")
data <- read.csv("fisheries.csv")
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Rshiny')
data <- read.csv("fisheries.csv")
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Rshiny')
data <- read.csv("fisheries.csv")
data <- read.csv("Rshiny/fisheries.csv")
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Rshiny')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Rshiny')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/Rshiny')
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
word_table <- as.data.frame(word_freqs)
wordcloud2(data = word_table, size = 2)
knitr::opts_chunk$set(echo = TRUE)
library(RColorBrewer)
library(wordcloud2)
library(readr)
library(dplyr)
library(tidyr)
library(magrittr)
library(ggplot2)
library(qrcode)
library(lattice)
data <- read.csv("fisheries.csv")
# Create a word cloud on capture and aquaculture
text <- c("R is a programming language for statistical computing and graphics supported by the R Core Team and the R Foundation for Statistical Computing. Created by statisticians Ross Ihaka and Robert Gentleman, R is used among data miners, bioinformaticians and statisticians for data analysis and developing statistical software. The core R language is augmented by a large number of extension packages containing reusable code and documentation.")
# Convert text to lowercase
text <- tolower(text)
# Remove punctuation and numbers
text <- gsub("[[:punct:]]", "", text)
text <- gsub("[[:digit:]]", "", text)
# Split text into words
word_list <- strsplit(text, " ")[[1]]
# Create a table of word frequencies
word_freqs <- table(word_list)
word_table <- as.data.frame(word_freqs)
wordcloud2(data = word_table, size = 2)
# Word cloud can be used for text analysis, which can quickly grasp the main themes or topics of a large text. Common words appear larger than less common words. Meanwhile, it can also used to create data presentation and Offer a visually appealing way to present textual data in presentations or reports.
# Limitations of word cloud includes lack of precision since word clouds provide a high-level overview but don't give precise insights or numbers about the frequency of words. Also, word cloud is not suitable for all data. Not all textual data is suitable for word cloud representation, especially texts where frequencies don't translate to importance.
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
View(word_table)
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
View(word_table)
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
library(tm)
install.packages("tm")
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
?getTermMatrix
??getTermMatrix
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/wordcloud')
install.packages("shinythemes")
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
shiny::runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
runApp('Desktop/Grinnell/Fall 2023/CSC-324/Lab4/histogram')
knitr::opts_chunk$set(echo = TRUE)
# The %in% operator in R is used to test if an element belongs to a set (or if multiple elements belong to a set). It returns a logical vector indicating whether the left-hand value (or values) can be found in the right-hand vector.
# Example 1: Basic Usage
4 %in% c(1, 2, 3, 4, 5)  # Returns TRUE
# Example 2: Using %in% with a Vector
c(1, 3, 5, 7) %in% c(1, 2, 3, 4, 5)  # Returns c(TRUE, TRUE, TRUE, FALSE)
# Example 3: Filtering Data Based on %in%
# Sample data frame
df <- data.frame(
item = c("apple", "banana", "cherry", "date", "eggplant"),
color = c("red", "yellow", "red", "brown", "purple")
)
# Filter data frame based on a list of desired colors
desired_colors <- c("red", "yellow")
filtered_df <- df[df$color %in% desired_colors, ]
print(filtered_df)
data <- read.csv("fisheries.csv")
data <- read.csv("histogram/fisheries.csv")
View(data)
subset_data <- data[data$total > 10000]
subset_data <- data[data$total > 10000, ]
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
par(mfrow=c(1,2))
plot(data$country, full_data$total, main="Full Data", xlab="Horsepower", ylab="MPG")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
par(mfrow=c(1,2))
plot(data$country, data$total, main="Full Data", xlab="Horsepower", ylab="MPG")
plot(data$country[1:10], data$total, main="Full Data", xlab="Horsepower", ylab="MPG")
plot(data$country[1:10], data$total[1:10], main="Full Data", xlab="Horsepower", ylab="MPG")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
par(mfrow=c(1,2))
library(ggplot2)
ggplot(data, aes(x=data$country, y = data$total)) +
geom_bar() +
labs(title="Your Title", x="Your X-axis Label", y="Count")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
par(mfrow=c(1,2))
library(ggplot2)
ggplot(data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Your Title", x="Your X-axis Label", y="Count")
#
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
par(mfrow=c(1,2))
library(ggplot2)
ggplot(data, aes(x=country[1:20], y=total[1:20])) +
geom_bar(stat="identity") +
labs(title="Your Title", x="Your X-axis Label", y="Count")
p1 <- ggplot(data, aes(x=capture, y=total)) +
geom_hex(bins=30) +
labs(title="Hexbin plot: Full Data")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
# mean for full data is 930283 while for the subset it is 1320704
par(mfrow=c(1,2))
library(ggplot2)
ggplot(data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Full Data", x="Country", y="Total Count")
ggplot(subset_data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Subset Data", x="Country", y="Total Count")
p1 <- ggplot(data, aes(x=capture, y=total)) +
geom_hex(bins=30) +
labs(title="Hexbin plot: Full Data")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
# mean for full data is 930283 while for the subset it is 1320704
library(ggplot2)
ggplot(data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Full Data", x="Country", y="Total Count")
ggplot(subset_data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Subset Data", x="Country", y="Total Count")
p1 <- ggplot(data, aes(x=capture, y=total)) +
geom_hex(bins=30) +
labs(title="Hexbin plot: Full Data")
data <- read.csv("histogram/fisheries.csv")
subset_data <- data[data$total > 10000, ]
mean_full_data <- mean(data$total)
mean_subset_data <- mean(subset_data$total)
# mean for full data is 930283 while for the subset it is 1320704
library(ggplot2)
ggplot(data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Full Data", x="Country", y="Total Count")
ggplot(subset_data, aes(x=country, y=total)) +
geom_bar(stat="identity") +
labs(title="Subset Data", x="Country", y="Total Count")
ggplot(data, aes(x=capture, y=total)) +
geom_hex(bins=30) +
labs(title="Hexbin plot: Full Data")
library(shiny); runApp('Desktop/CSC324_Individual_Project/graphing.R')
runApp('Desktop/CSC324_Individual_Project')
install.packages('rsconnect')
install.packages("rsconnect")
install.packages("rsconnect")
install.packages("rsconnect")
rsconnect::setAccountInfo(name='tml17', token='B628BE633F44E87E2AE859AFF6777000', secret='+Q1r6qx0mF79IyVcUzmad+9TQp74YzvIIA9LAD75')
library(rsconnect)
shiny::runApp('Desktop/CSC324_Individual_Project')
getwd()
ls
rsconnect::deployApp('\Desktop\CSC324_Individual_Project/')
rsconnect::deployApp('\Desktop\CSC324_Individual_Project')
rsconnect::deployApp('/Desktop/CSC324_Individual_Project')
setwd('/Desktop')
setwd('C:/Desktop')
rsconnect::deployApp('CSC324_Individual_Project')
rsconnect::deployApp('/Desktop/CSC324_Individual_Project')
rsconnect::deployApp('/Desktop/CSC324_Individual_Project\')
deployApp()
rsconnect::deployApp('CSC324_Individual_Project')
knitr::opts_chunk$set(echo = TRUE)
time_log <- read.csv("data/time_log.csv")
time_log <- read.csv("/data/time_log.csv")
time_log <- read_csv("data/time_log.csv")
time_log <- read.csv("data/time_log.csv")
getwd()
setwd("/Users/chenxingliu/Desktop/CSC324_Individual_Project")
time_log <- read.csv("data/time_log.csv")
View(time_log)
time_log <- read.csv("data/time_log.csv")
View(time_log)
time_log <- read.csv("data/time_log.csv")
summary(time_log)
time_log <- read.csv("data/time_log.csv")
# Required libraries
library(ggplot2)
library(tidyverse)
# Read the log
log_df <- read.csv("time_log.csv")
time_log <- read.csv("data/time_log.csv")
# Required libraries
library(ggplot2)
library(tidyverse)
# Create a bar chart visualizing hours spent on each task
ggplot(time_log, aes(x = Task, y = Hours, fill = Status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Time Spent on Tasks", x = "Tasks", y = "Hours Spent") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
# Required libraries
library(ggplot2)
library(tidyverse)
# Create a bar chart visualizing hours spent on each task
ggplot(time_log, aes(x = Task, y = Hours, fill = Status)) +
geom_bar(stat = "identity", position = "dodge") +
labs(title = "Time Spent on Tasks", x = "Tasks", y = "Hours Spent") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
